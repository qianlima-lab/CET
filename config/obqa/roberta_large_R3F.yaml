# LM_ONLY

# General
use_wandb: True 
debug: False 
run_name: roberta_large_R3F
experiment_model: lm_only
pretrain_model: roberta-large
dataset: obqa
input_format: each_option
is_R3F: True
R3F_eps: 1e-5
R3F_lambda: 1.0
R3F_noise_type: 'uniform'

# Training
n_epochs: 200
max_epochs_before_stop: 10
unfreeze_epoch: 0 
accumulate_batch_size: 128
batch_size: 8
eval_batch_size: 8
inhouse: False
lr: 1e-5
optim: radam 